#!/usr/bin/env python
"""
Exemple d'utilisation de UnifiedLLM avec le gestionnaire de credentials.
"""

import asyncio
import os
from typing import Dict, List, Optional

from unified_llm import UnifiedLLM, ModelConfig
from credential_manager import CredentialSource


async def async_example():
    """Exemple d'utilisation asynchrone."""
    # Initialiser le client en mode asynchrone
    llm = UnifiedLLM()
    
    # Vérifier les fournisseurs disponibles
    providers = llm.list_providers()
    print(f"Fournisseurs disponibles: {providers}")
    print(f"Fournisseur actif: {llm.get_provider()}")
    
    # Créer une configuration
    config = ModelConfig(
        model_name="claude-3-haiku-20240307" if llm.get_provider() == "claude" else "qwen2.5-7b-instruct-1m",
        temperature=0.7,
        max_tokens=500
    )
    
    # Créer une conversation
    conversation = llm.create_conversation(
        model_config=config,
        system_message="Tu es un assistant utile, concis et précis."
    )
    
    # Envoyer un message et recevoir la réponse de manière asynchrone
    response = await llm.chat_async(
        messages=[llm.create_message("user", "Explique-moi l'intelligence artificielle en 3 phrases.")],
        config=config
    )
    
    print(f"\nRéponse asynchrone:\n{response}")
    
    # Exemple d'embedding asynchrone
    embeddings = await llm.embed_async("Exemple de texte pour embedding")
    print(f"\nEmbedding asynchrone de longueur: {len(embeddings)}")
    
    return conversation


def sync_example():
    """Exemple d'utilisation synchrone."""
    # Initialiser le client en mode synchrone
    llm = UnifiedLLM()
    
    # Créer une configuration
    config = ModelConfig(
        model_name="claude-3-haiku-20240307" if llm.get_provider() == "claude" else "qwen2.5-7b-instruct-1m",
        temperature=0.7,
        max_tokens=500
    )
    
    # Envoyer un message et recevoir la réponse de manière synchrone
    response = llm.chat(
        messages=[llm.create_message("user", "Qu'est-ce que le machine learning?")],
        config=config
    )
    
    print(f"\nRéponse synchrone:\n{response}")
    
    # Exemple d'embedding synchrone
    embeddings = llm.embed("Exemple de texte pour embedding")
    print(f"\nEmbedding synchrone de longueur: {len(embeddings)}")


def credential_management_example():
    """Exemple de gestion des credentials."""
    print("\n" + "="*50)
    print("GESTION DES CREDENTIALS")
    print("="*50 + "\n")
    
    # Initialisation avec clé API explicite
    api_key = os.environ.get("ANTHROPIC_API_KEY", "dummy_key_for_demo")
    llm = UnifiedLLM(provider="claude", api_key=api_key)
    
    # Vérifier la source de la clé API
    from credential_manager import CredentialManager
    cred_manager = CredentialManager()
    
    # Afficher les fournisseurs configurés
    configured = cred_manager.get_configured_providers()
    print(f"Fournisseurs configurés: {configured}")
    
    # Afficher les sources des credentials
    for provider in ["claude", "lmstudio"]:
        source = cred_manager.credential_source(provider, "api_key")
        if source:
            print(f"Source de la clé API pour {provider}: {source.value}")
        else:
            print(f"Pas de clé API configurée pour {provider}")
    
    # Démonstration de l'ajout d'une nouvelle clé API
    print("\nAjout d'une nouvelle clé API pour OpenAI...")
    cred_manager.set_api_key("openai", "sk-dummy-openai-key-for-demo", CredentialSource.CONFIG_FILE)
    
    # Vérifier la configuration après ajout
    print("\nVérification de la configuration après ajout:")
    for provider in ["claude", "lmstudio", "openai"]:
        credentials = cred_manager.get_credentials(provider)
        if credentials:
            print(f"Credentials pour {provider}: {credentials}")
        else:
            print(f"Pas de credentials pour {provider}")
    
    # Nettoyage (pour la démo)
    print("\nNettoyage des credentials de démonstration...")
    cred_manager.clear_credentials("openai", CredentialSource.CONFIG_FILE)


def multi_provider_example():
    """Exemple d'utilisation avec plusieurs fournisseurs."""
    print("\n" + "="*50)
    print("UTILISATION AVEC PLUSIEURS FOURNISSEURS")
    print("="*50 + "\n")
    
    # Initialisation avec détection automatique
    llm = UnifiedLLM()
    initial_provider = llm.get_provider()
    
    # Créer une configuration générique
    config = ModelConfig(
        model_name="claude-3-haiku-20240307" if initial_provider == "claude" else "qwen2.5-7b-instruct-1m",
        temperature=0.7,
        max_tokens=500
    )
    
    # Premier message avec le fournisseur par défaut
    print(f"Utilisation du fournisseur: {initial_provider}")
    response1 = llm.chat(
        messages=[llm.create_message("user", "Qui es-tu?")],
        config=config
    )
    print(f"\nRéponse de {initial_provider}:\n{response1}")
    
    # Tenter de changer de fournisseur si possible
    providers = llm.list_providers()
    if len(providers) > 1:
        # Changer pour un autre fournisseur
        other_provider = [p for p in providers if p != initial_provider][0]
        print(f"\nChangement de fournisseur: {initial_provider} -> {other_provider}")
        
        try:
            llm.set_provider(other_provider)
            
            # Mettre à jour la configuration pour le nouveau fournisseur
            config = ModelConfig(
                model_name="claude-3-haiku-20240307" if other_provider == "claude" else "qwen2.5-7b-instruct-1m",
                temperature=0.7,
                max_tokens=500
            )
            
            # Message avec le nouveau fournisseur
            response2 = llm.chat(
                messages=[llm.create_message("user", "Qui es-tu?")],
                config=config
            )
            print(f"\nRéponse de {other_provider}:\n{response2}")
            
        except Exception as e:
            print(f"\nErreur lors du changement de fournisseur: {e}")
    else:
        print(f"\nUn seul fournisseur disponible: {initial_provider}")


if __name__ == "__main__":
    # Exemple synchrone
    print("\n" + "="*50)
    print("EXEMPLE SYNCHRONE")
    print("="*50)
    sync_example()
    
    # Exemple asynchrone
    print("\n" + "="*50)
    print("EXEMPLE ASYNCHRONE")
    print("="*50)
    asyncio.run(async_example())
    
    # Exemple de gestion des credentials
    credential_management_example()
    
    # Exemple multi-fournisseurs
    multi_provider_example()
